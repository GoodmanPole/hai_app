import streamlit as st
import os
import faiss
import numpy as np
import pickle
from openai import OpenAI
from anthropic import Anthropic
from sentence_transformers import SentenceTransformer
from pydantic import BaseModel
from PIL import Image






# Set API Keys
ANTHROPIC_API_KEY="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"
OPENAI_API_KEY="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"

# Initialize Streamlit App
# UI Setup
st.set_page_config(page_title="MindBuddy RAG Chat", layout="centered")

# Load Avatars (make sure these files exist in an 'assets/' folder)
user_avatar = Image.open("assets/user_avatar.png")  # optional, replace if you want
bot_avatar = Image.open("assets/mascot.png")        # penguin or similar mascot


st.title("ðŸ“„ RAG-Powered Text File QA with Anthropic LLM")
st.write("Reading text files from a folder, ask questions, and get intelligent responses!")

# Folder containing text files
# Folder containing text files
TEXT_FOLDER = "Resources\\Cognitive Therapy Behavior"  # Change to your folder path
INDEX_FILE = f"faiss_index_Cognitive_Therapy_Behavior.bin"
METADATA_FILE = f"metadata_Cognitive_Therapy_Behavior.pkl"

# Load text data
all_texts = []
file_names = []
for filename in os.listdir(TEXT_FOLDER):
    if filename.endswith(".txt"):
        with open(os.path.join(TEXT_FOLDER, filename), "r", encoding="utf-8", errors="ignore") as file:
            all_texts.append(file.read())
            file_names.append(filename)


# Validate input data using Pydantic
class Document(BaseModel):
    content: str
    filename: str


documents = [Document(content=text, filename=name) for text, name in zip(all_texts, file_names)]


# Function to save FAISS index
def save_faiss_index(index, file_path):
    faiss.write_index(index, file_path)


def load_faiss_index(file_path):
    return faiss.read_index(file_path)


def save_metadata(metadata, file_path):
    with open(file_path, "wb") as f:
        pickle.dump(metadata, f)


def load_metadata(file_path):
    with open(file_path, "rb") as f:
        return pickle.load(f)


model = SentenceTransformer("all-MiniLM-L6-v2")

# Check if a stored FAISS index and metadata exist
if os.path.exists(INDEX_FILE) and os.path.exists(METADATA_FILE):
    st.write("Loading existing FAISS index...")
    index = load_faiss_index(INDEX_FILE)
    documents = load_metadata(METADATA_FILE)
else:
    st.write("Creating FAISS index from scratch...")

    # Load Sentence Transformer for embedding

    embeddings = model.encode([doc.content for doc in documents])

    # Create FAISS index
    dimension = embeddings.shape[1]
    index = faiss.IndexFlatL2(dimension)
    index.add(np.array(embeddings, dtype=np.float32))

    # Save the FAISS index and metadata
    save_faiss_index(index, INDEX_FILE)
    save_metadata(documents, METADATA_FILE)
    st.write("FAISS index saved for future use.")

# Initialize OpenAI API
client = OpenAI(api_key=OPENAI_API_KEY)


# def retrieve_and_answer(query):
#     query_embedding = model.encode([query])
#     D, I = index.search(np.array(query_embedding, dtype=np.float32), k=3)
#     retrieved_texts = [documents[i].content for i in I[0] if i < len(documents)]
#     combined_text = "\n\n".join(retrieved_texts)
#
#     response = client.chat.completions.create(
#         model="gpt-4",
#         messages=[
#             {"role": "system",
#              "content": "You are an AI assistant that provides accurate responses based on retrieved documents."},
#             {"role": "user",
#              "content": f"The question is in persian translate to english first, and then use the following retrieved texts to answer the question, at the translate the answer back into persian, and try to stay accurate in translating: {query}\n\nRetrieved Texts:\n{combined_text}"}
#         ],
#         max_tokens=200
#     )
#     return response.choices[0].message.content.strip()


#Initialize Anthropic API
client = Anthropic(api_key=ANTHROPIC_API_KEY)


# Store chat history
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []


def retrieve_and_answer(query):
    query_embedding = model.encode([query])
    D, I = index.search(np.array(query_embedding, dtype=np.float32), k=3)
    retrieved_texts = [documents[i].content for i in I[0] if i < len(documents)]
    combined_text = "\n\n".join(retrieved_texts)

    messages = st.session_state.chat_history + [
        {"role": "user",
         "content": f"The question is in persian translate to english first, and then use the following retrieved texts to answer the question: {query}\n\nRetrieved Texts:\n{combined_text}"}
    ]

    response = client.messages.create(
        model="claude-2",
        max_tokens=200,
        system="You are an AI assistant that provides accurate responses based on retrieved documents.",
        messages=messages
    )

    reply = response.content[0].text.replace('\n', '').strip()

    # Store conversation history
    st.session_state.chat_history = [{"role": "user", "content": query}, {"role": "assistant", "content": reply}]


    return reply


# Chat interface
st.write("### Chat with the AI")
for message in st.session_state.chat_history:
    st.write(f"**{message['role'].capitalize()}**: {message['content']}")

query = st.text_input("Type your message:")
if query:
    response = retrieve_and_answer(query)
    st.text_area("### Answer:", response, height=1000)



	